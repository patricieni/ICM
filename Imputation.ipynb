{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os \n",
    "from datetime import timedelta\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data_path = str(Path(os.getcwd())) + \"/data/\"\n",
    "\n",
    "def write_to_pickle(dataframe, name):\n",
    "    dataframe.to_pickle(data_path + name + \".pickle\")\n",
    "def read_from_pickle(name): \n",
    "    return pd.read_pickle(data_path + name + \".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = read_from_pickle('final_dataset')\n",
    "df_no_censoring = read_from_pickle('final_dataset_no_censoring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2635, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2086, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_censoring.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop ID so that MICE imputation works\n",
    "df.drop(['ID'], axis=1,inplace=True)\n",
    "df_no_censoring.drop(['ID'], axis=1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "# checking how many observations we have with different numbers of NA data across variables\n",
    "no_NAN = df.dropna(thresh = 35)\n",
    "no_NAN_censoring = df.dropna(thresh = 35)\n",
    "print(len(no_NAN), len(no_NAN_censoring))\n",
    "\n",
    "df.drop(\"RX\", axis = 1, inplace=True)\n",
    "df.drop(\"CHEM\", axis = 1, inplace=True)\n",
    "\n",
    "df_no_censoring.drop(\"RX\", axis = 1, inplace=True)\n",
    "df_no_censoring.drop(\"CHEM\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export dataset for imputation\n",
    "df.to_csv('data/preimputation_dataset_with_censoring_18022018.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/preimputation_datasets_without_censoring_18022018.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we will need to import the imputed dataset, which used life expectancy for the information it contains, and replace\n",
    "this variable with the same column from the pre imputation dataset, since we are not interested in the imputed target variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_alex = \"\"\n",
    "df_imputed = pd.read_csv(path_alex + \"/imputed_dataset_with_censoring_18022018\")\n",
    "df_imputed['life_expectancy'] = df_final_kps['life_expectancy']\n",
    "df_imputed['life_expectancy'].isnull().value_counts()\n",
    "\n",
    "df_imputed.to_csv(\"Dropbox/Healthcare work Patric/imputed_dataset_with_censoring_16022018.csv\")\n",
    "df_imputed_knn = pd.read_csv(\"Dropbox/Healthcare work Patric/imputed_dataset_with_censoring_16.02.2018_kNN_before life expectancy reset.csv\")\n",
    "df_imputed_knn['life_expectancy'] = df_final_kps['life_expectancy']\n",
    "df_imputed_knn['life_expectancy'].isnull().value_counts()\n",
    "df_imputed_knn.to_csv(\"Dropbox/Healthcare work Patric/imputed_dataset_with_censoring_16022018_kNN.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below is R imputation for MICE, Amelia, KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MICE imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set directory\n",
    "\n",
    "setwd(\"Dropbox/Healthcare work Patric\")\n",
    "\n",
    "require mice package\n",
    "\n",
    "require(mice)\n",
    "\n",
    "load dataset\n",
    "\n",
    "dataset = read.csv(\"imputation_set_24012018.csv\", header=TRUE, na.strings = '')\n",
    "summary(dataset)\n",
    "\n",
    "load VIM library for missing data visualization\n",
    "\n",
    "library(VIM)\n",
    "aggr(dataset, prop = F, numbers = T)\n",
    "\n",
    "matrixplot(dataset, interactive = F)\n",
    "\n",
    "marginplot(dataset[,c(\"IK\",\"IDH_TERT\")])\n",
    "\n",
    "code IDH_TERT and X1p19q_codel as factors so that R/MICE doesnt treat them as continuous\n",
    "\n",
    "dataset$IDH_TERT <- as.factor(dataset$IDH_TERT)\n",
    "\n",
    "dataset$X1p19q_codel <- as.factor(dataset$X1p19q_codel)\n",
    "\n",
    "run mice imputation with 20 iterations\n",
    "\n",
    "imp <- mice(dataset, maxit = 20)\n",
    "\n",
    "inspect methods used for imputing each variable\n",
    "\n",
    "imp$method\n",
    "\n",
    "#Gender      Tumor_type     Tumor_grade        Gene_P53       Gene_Mgmt       Gene_Egfr       Gene_Mdm2 \n",
    "#    \"\"              \"\"              \"\"       \"polyreg\"        \"logreg\"        \"logreg\"        \"logreg\" \n",
    "#     Gene_Cdk4        Gene_P16   Gene_Ihc_Atrx      Gene_Ch10Q       Gene_Ch9P  Tumor_Location  Tumor_Position \n",
    "#       \"logreg\"        \"logreg\"       \"polyreg\"        \"logreg\"       \"polyreg\"       \"polyreg\"       \"polyreg\" \n",
    "#   Surgery_type     Age_surgery life_expectancy             IDH            TERT        IDH_TERT    X1p19q_codel \n",
    "#      \"polyreg\"              \"\"              \"\"       \"polyreg\"        \"logreg\"       \"polyreg\"        \"logreg\" \n",
    "#             IK \n",
    "#          \"pmm\" \n",
    "\n",
    "Inspect convergenve\n",
    "\n",
    "plot(imp)\n",
    "\n",
    "stripplot(imp, pch = 20, cex = 1.2)\n",
    "\n",
    "export the imputed dataset\n",
    "\n",
    "write.csv(complete(imp), file = \"imputed_dataset_no_censoring_16022018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amelia imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setwd(Dropbox/Healthcare work Patric)\n",
    "\n",
    "dataset = read.csv(\"imputation_dataset_no_censoring_24022018\", header = TRUE, na.strings = '')\n",
    "\n",
    "load Amelia\n",
    "\n",
    "library(Amelia)\n",
    "\n",
    "run imputation\n",
    "\n",
    "noms = categorical variables\n",
    "\n",
    "ords = ordinal variables\n",
    "\n",
    "idvars = nominal variables that should not be imputed\n",
    "\n",
    "if running Amelia on full dataset, it will throw an error. you need to remove either Tumor_type of Tumor_grade\n",
    "since removing Tumor_type converges faster, I removed Tumor_grade by adding it to idvars option\n",
    "Since both Tumor_type and Tumor_grade variables have no missing data, this does not hinder us at all\n",
    "\n",
    "a.out <- amelia(dataset, m=1, noms = c(\"Gender\", \"Tumor_grade\", \"Gene_P53\", \"Gene_Mgmt\", \"Gene_Egfr\", \"Gene_Mdm2\", \n",
    "                                       \"Gene_Cdk4\", \"Gene_P16\", \"Gene_Ihc_Atrx\", \"Gene_Ch10Q\", \"Gene_Ch9P\", \n",
    "                                       \"Tumor_Location\", \"Tumor_Position\", \"Surgery_type\", \"IDH\", \"TERT\", \n",
    "                                       \"X1p19q_codel\"), ords = c(\"IDH_TERT\"), idvars = c(\"RX\", \"CHEM\", \"Tumor_type\"))\n",
    "                                       \n",
    "                                       \n",
    "get key messages post imputation, including \"Normal EM convergence\"\n",
    "\n",
    "a.out    \n",
    "\n",
    "get full summary of output dataset\n",
    "\n",
    "summary(a.out)\n",
    "\n",
    "Post imputation diagnostic graphs\n",
    "\n",
    "plot(a.out, which.vars = 4:15)\n",
    "\n",
    "overimpute(a.out, var = \"IDH_TERT\")\n",
    "\n",
    "overimpute(a.out, var = \"IK\")\n",
    "\n",
    "export dataset. Here a.out contains only one imputed dataset. If it contained 5, this would export each of them in a csv \n",
    "named file.stem+1, file.stem+2...\n",
    "\n",
    "write.amelia(obj=a.out, file.stem = \"imputed_dataset_no_censoring_24022018_Amelia\")\n",
    "\n",
    "we repeat the same with the censured dataset. However, this time Amelia throws a collinearity error again, even when run\n",
    "with the same parameters as for non censored dataset\n",
    "As such, we pass \"life expectancy\" as an idvars to avoid collinearity issue\n",
    "\n",
    "a.out <- amelia(dataset, m=1, noms = c(\"Gender\", \"Tumor_grade\", \"Gene_P53\", \"Gene_Mgmt\", \"Gene_Egfr\", \"Gene_Mdm2\", \n",
    "                                                                                \"Gene_Cdk4\", \"Gene_P16\", \"Gene_Ihc_Atrx\", \"Gene_Ch10Q\", \"Gene_Ch9P\", \n",
    "                                                                                \"Tumor_Location\", \"Tumor_Position\", \"Surgery_type\", \"IDH\", \"TERT\", \n",
    "                                                                                \"X1p19q_codel\"), \n",
    "                                                                                \n",
    "                                                                                \n",
    "                                                                                                   ords = c(\"IDH_TERT\"), idvars = c(\"Tumor_type\", \"life_expectancy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset <- read.csv(\"imputation_dataset_no_censoring_24022018\", header=TRUE, na.strings = \"\")\n",
    "\n",
    "dataset$IDH_TERT <- as.factor(dataset$IDH_TERT)\n",
    "\n",
    "dataset$X1p19q_codel <- as.factor(dataset$X1p19q_codel)\n",
    "\n",
    "imp <- kNN(dataset, k = 10)\n",
    "\n",
    "write.csv(imp, \"imputed_dataset_with_censoring_16.02.2018_kNN.csv\")\n",
    "\n",
    "Same but for censored dataset\n",
    "\n",
    "dataset <- read.csv(\"imputation_dataset_with_censoring_24022018\", header=TRUE, na.strings = \"\")\n",
    "\n",
    "dataset$IDH_TERT <- as.factor(dataset$IDH_TERT)\n",
    "\n",
    "dataset$X1p19q_codel <- as.factor(dataset$X1p19q_codel)\n",
    "\n",
    "imp <- kNN(dataset, k = 10)\n",
    "\n",
    "write.csv(imp, \"imputed_dataset_with_censoring_26022018_kNN.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
