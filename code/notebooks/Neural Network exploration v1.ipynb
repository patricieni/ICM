{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Neural Network libraries in Python:\n",
    "# Training a Feedforward Neural Network for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Benchmark: Logistic Regression (scikit-learn)\n",
    "    \n",
    "#### 2. Classification\n",
    "    2.1 Benchmark\n",
    "    2.2 Keras NN\n",
    "    2.3 Ensamble of models\n",
    "\n",
    "#### 3. Regression\n",
    "    3.1 Benchmark\n",
    "    3.2 Keras NN\n",
    "    \n",
    "#### 4. PyBrain\n",
    "    4.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd().split('ICM')[0], 'ICM', 'code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%matplotlib inline \n",
    "import time, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMC_basedir = os.getcwd().split('code')[0]\n",
    "DATA_AMELIA_FILE = os.path.join(IMC_basedir, 'data/imputed_dataset_no_censoring_26022018_Amelia1.csv')\n",
    "DATA_MICE_FILE = os.path.join(IMC_basedir, 'data/imputed_dataset_no_censoring_26022018_MICE.csv')\n",
    "TRAIN_FILE = os.path.join(IMC_basedir, 'data/amelia_train')\n",
    "TEST_FILE = os.path.join(IMC_basedir, 'data/amelia_test')\n",
    "MODEL_DIR = os.path.join(IMC_basedir, 'data/amelia_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, labels = utils.process_amelia(DATA_AMELIA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_r, Y_train_r, X_test_r, Y_test_r = utils.get_train_test_data(df, regression=True, train_size=0.8)\n",
    "X_train_c, Y_train_c, X_test_c, Y_test_c = utils.get_train_test_data(df, regression=False, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Benchmark Logistic Regression (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1.5year       0.63      0.71      0.67       198\n",
      "     4years       0.41      0.38      0.39       137\n",
      "       more       0.72      0.58      0.64        83\n",
      "\n",
      "avg / total       0.57      0.58      0.57       418\n",
      "\n",
      "Accuracy: 0.5765550239234449\n",
      "Mean square error (MSE): 0.54\n",
      "R^2: 0.58\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEbCAYAAAD6TW79AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCRhlLhFRBJGiVtEJGH+H1glcASvrKhaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc9ab8536d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create logistic regression object\n",
    "regr = linear_model.LogisticRegression()             \n",
    "regr.fit(X_train_c, Y_train_c) \n",
    "\n",
    "Y_pred = regr.predict(X_test_c)\n",
    "            \n",
    "utils.plot_report(Y_test_c, Y_pred, labels)\n",
    "\n",
    "# print ('Coefficients:', regr.coef_, regr.intercept_ )               \n",
    "print(\"Mean square error (MSE): %.2f\"\n",
    "      % np.mean((Y_pred - Y_test_c) ** 2))      # The mean square error\n",
    "print ('R^2: %.2f' % regr.score(X_test_c, Y_test_c) )  # Explained variance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error (MSE): 3023735.37\n",
      "R^2: 0.00\n"
     ]
    }
   ],
   "source": [
    "regr = LinearSVC()\n",
    "regr.fit(X_train_r, Y_train_r) \n",
    "\n",
    "Y_pred = regr.predict(X_test_r)\n",
    "\n",
    "# print ('Coefficients:', regr.coef_, regr.intercept_ )               \n",
    "print(\"Mean square error (MSE): %.2f\"\n",
    "      % np.mean((Y_pred - Y_test_r) ** 2))      # The mean square error\n",
    "print ('R^2: %.2f' % regr.score(X_test_r, Y_test_r) )  # Explained variance score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Benchmark Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=0)\n",
    "svc.fit(X_train_c, Y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1.5year       0.52      0.99      0.68       198\n",
      "     4years       1.00      0.02      0.04       137\n",
      "       more       0.92      0.40      0.55        83\n",
      "\n",
      "avg / total       0.76      0.56      0.45       418\n",
      "\n",
      "Accuracy: 0.5574162679425837\n",
      "Mean square error (MSE): 0.81\n",
      "R^2: 0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEbCAYAAAD6TW79AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc90dd63c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_pred = svc.predict(X_test_c)\n",
    "            \n",
    "utils.plot_report(Y_test_c, Y_pred, labels)\n",
    "\n",
    "# print ('Coefficients:', regr.coef_, regr.intercept_ )               \n",
    "print(\"Mean square error (MSE): %.2f\"\n",
    "      % np.mean((Y_pred - Y_test_c) ** 2))      # The mean square error\n",
    "print ('R^2: %.2f' % regr.score(X_test_c, Y_test_c) )  # Explained variance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(random_state=0)\n",
    "svc.fit(X_train_r, Y_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error (MSE): 3293755.38\n",
      "R^2: 0.00\n"
     ]
    }
   ],
   "source": [
    "Y_pred = svc.predict(X_test_r)\n",
    "            \n",
    "# print ('Coefficients:', regr.coef_, regr.intercept_ )               \n",
    "print(\"Mean square error (MSE): %.2f\"\n",
    "      % np.mean((Y_pred - Y_test_r) ** 2))      # The mean square error\n",
    "print ('R^2: %.2f' % regr.score(X_test_r, Y_test_r) )  # Explained variance score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Classification: Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need the full dataset for cross validation\n",
    "X = df.copy(deep=True)\n",
    "\n",
    "Y = np.array(X['life_expectancy_bin'])\n",
    "# remove columns\n",
    "X.drop('life_expectancy', axis = 1, inplace=True)\n",
    "X.drop('life_expectancy_bin', axis = 1, inplace=True)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=54, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cross_val_score(estimator, X, Y, cv=KFold(n=X.shape[0], n_folds=2, shuffle=True))\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Classification: Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Dense(108, input_shape=(54,), kernel_initializer='normal', activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_dim=54))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.add(Dense(input_dim=54, output_dim=12, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(input_dim=12, output_dim=12, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(output_dim=1, activation='softmax'))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "# 3\n",
    "#tbCallBack = keras.callbacks.TensorBoard(log_dir='/tmp/keras_logs', write_graph=True)\n",
    "\n",
    "# 4\n",
    "#model.compile(loss='mean_squared_error', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(np.array(X_train), np.array(to_categorical(Y_train)), \n",
    "                 epochs=600, batch_size=128,  verbose=1, validation_split=0.3)#, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(np.array(X_train), np.array(to_categorical(Y_train)), \n",
    "                 epochs=120, batch_size=128,  verbose=0, validation_split=0.3)#, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = Y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_report(Y_test, Y_pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Classification: Ensamble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_dim = 54, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mp = mlp_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = mp.fit(np.array(X_train_c), np.array(to_categorical(Y_train_c)), epochs=600, batch_size=128,  verbose=0, \n",
    "              validation_split=0.3)#, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create 5 models to ensemble\n",
    "model1 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "model2 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "model3 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "model4 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "model5 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "\n",
    "ensemble_clf = VotingClassifier(estimators = [('model1', model1), ('model2', model2), \n",
    "                                              ('model3', model3), ('model4', model4), \n",
    "                                              ('model5', model5)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble_clf.fit(np.array(X_train), np.array(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = ensemble_clf.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_report(Y_test, Y_pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Regression: Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_kfolds(regressor, x, y, kfolds = [5]):\n",
    "    for k_folds in kfolds:\n",
    "        # evaluate model with standardized dataset\n",
    "        np.random.seed(182)\n",
    "        estimators = []\n",
    "        #estimators.append(('standardize', StandardScaler()))\n",
    "        estimators.append(('mlp', regressor))\n",
    "        pipeline = Pipeline(estimators)\n",
    "        kfold = KFold(n=X.shape[0], n_folds=k_folds)\n",
    "        results = cross_val_score(pipeline, x, y, cv=kfold)\n",
    "        print(\"K_folds {}: \\nMean {} \\nStd {}\".format(k_folds, results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need full dataset for cross validation\n",
    "X = df.copy(deep=True)\n",
    "\n",
    "Y = np.array(X['life_expectancy'])\n",
    "# remove columns\n",
    "X.drop('life_expectancy', axis = 1, inplace=True)\n",
    "X.drop('life_expectancy_bin', axis = 1, inplace=True)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=54, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[metrics.MAPE,\n",
    "                                                                        metrics.MSLE,\n",
    "                                                                        metrics.MAE])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm = baseline_model()\n",
    "hist = bm.fit(np.array(X_train_r), np.array(Y_train_r), \n",
    "                 epochs=600, batch_size=128,  verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kfolds(KerasRegressor(build_fn=baseline_model, nb_epoch=150, batch_size=128, verbose=0), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm.evaluate(np.array(X_test_r), np.array(Y_test_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Regression: Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(54, kernel_initializer=\"normal\", input_dim=54, activation=\"relu\"))\n",
    "    model.add(Dense(27, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(15, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kfolds(KerasRegressor(build_fn=larger_model, nb_epoch=150, batch_size=128, verbose=0), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(540, kernel_initializer=\"normal\", input_dim=54, activation=\"relu\"))\n",
    "    model.add(Dense(270, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kfolds(KerasRegressor(build_fn=wider_model, nb_epoch=150, batch_size=128, verbose=0), X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Model showdown\n",
    "\n",
    "Different approach for Classification vs. Regression using Neural Network:\n",
    "- Training examples: Rn x {class_1, ..., class_n} (one-hot encoding) vs Rn x Rm\n",
    "- Last layer: softmax vs linear / sigmoid\n",
    "- Loss function: Cross entropy vs MSE / Absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, kernel_initializer=\"normal\", input_dim=54))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "    \n",
    "model.compile(optimizer = optimizers.SGD(lr = 0.001), loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(np.array(X_train), np.array(Y_train), epochs = 100, verbose = 1)\n",
    "\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.legend(['training', 'validation'], loc = 'upper left')\n",
    "# plt.show()\n",
    "\n",
    "results = model.evaluate(np.array(X_test), np.array(Y_test))\n",
    "print('\\nTest accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pybrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/pybrain/pybrain.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 PyBrain: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybrain.structure import SigmoidLayer, LinearLayer, TanhLayer, ReluLayer, SoftmaxLayer\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "import pybrain.tools.shortcuts as pb\n",
    "import numpy, math\n",
    "\n",
    "# Build the dataset\n",
    "xvalues = np.array(X_train_r)\n",
    "yvalues = np.array(Y_train_r)\n",
    "ds = SupervisedDataSet(54, 1)\n",
    "for x, y in zip(xvalues, yvalues):\n",
    "    ds.addSample((x), (y))\n",
    "    \n",
    "# Build the NN\n",
    "nn1 = pb.buildNetwork(54,  # 1 input node\n",
    "                   #108,    # number of nodes in 1st hidden layer\n",
    "                   54,     # number of nodes in 4th hidden layer\n",
    "                   1,     # 1 output node\n",
    "                   bias = False,\n",
    "                   hiddenclass = SigmoidLayer,\n",
    "                   outclass = LinearLayer )\n",
    "\n",
    "# Train the NN\n",
    "trainer = BackpropTrainer(nn1, ds, learningrate = 0.01, weightdecay=0.01, momentum=0.02) #, verbose = True)\n",
    "train_mse, validation_mse = trainer.trainUntilConvergence(maxEpochs = 20, continueEpochs=5, validationProportion=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note on some of the parameters\n",
    "\n",
    "**validationProportion**: ratio of the dataset that is used for the validation dataset.\n",
    "If maxEpochs is given, at most that many epochs are trained. Each time validation error hits a minimum, try for continueEpochs # epochs to find a better one.\n",
    "\n",
    "**Epoch**: one epoch means that every example has been seen once. It is preferable to track epochs rather than iterations since \n",
    "the number of iterations depends on the arbitrary setting of batch size. Batchs are used for example in the minibatch method,\n",
    "for example, for 1000 examples, the NN is trained on examples 1-100, then examples 101-201, etc.\n",
    "\n",
    "**Momentum**: 0 < m < 1 is a global parameter which must be determined by trial and error. Momentum simply adds a fraction m of the previous weight update to the current one. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum. It is otherefore often necessary to reduce the global learning rate  when using a lot of momentum (m close to 1). If you combine a high learning rate with a lot of momentum, you will rush past the minimum with huge steps! When the gradient keeps changing direction, momentum will smooth out the variations. Adding a momentum can help to speed up convergence to the minimum by damping oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curves\n",
    "plt.clf()\n",
    "plt.plot(range(len(train_mse)), np.sqrt(train_mse), color='blue', label='training error')\n",
    "plt.plot(range(len(validation_mse)), np.sqrt(validation_mse), color='red', label='validation error')\n",
    "plt.title('Learning curves: loss(=RMSE) as a function of Epochs')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
