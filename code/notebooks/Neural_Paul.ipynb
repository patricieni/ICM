{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Neural Network libraries in Python:\n",
    "# Training a Feedforward Neural Network for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Benchmark: Logistic Regression (scikit-learn)\n",
    "    \n",
    "#### 2. Classification\n",
    "    2.1 Benchmark\n",
    "    2.2 Keras NN\n",
    "    2.3 Ensamble of models\n",
    "\n",
    "#### 3. Regression\n",
    "    3.1 Benchmark\n",
    "    3.2 Keras NN\n",
    "    \n",
    "#### 4. Others\n",
    "    4.1 PyBrain\n",
    "    4.2 Tensorflow (Deep Neural Network Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.join(os.getcwd().split('ICM')[0], 'ICM', 'code'))\n",
    "sys.path.append(os.path.join(os.getcwd().split('ICM')[0], 'ICM', 'code', 'notebooks', 'libs'))\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation, Dense, BatchNormalization, Dropout\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%matplotlib inline \n",
    "import time, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMC_basedir = os.getcwd().split('code')[0]\n",
    "DATA_AMELIA_FILE = os.path.join(IMC_basedir, 'data/imputed_dataset_no_censoring_26022018_Amelia1.csv')\n",
    "DATA_MICE_FILE = os.path.join(IMC_basedir, 'data/imputed_dataset_no_censoring_26022018_MICE.csv')\n",
    "TRAIN_FILE = os.path.join(IMC_basedir, 'data/amelia_train')\n",
    "TEST_FILE = os.path.join(IMC_basedir, 'data/amelia_test')\n",
    "MODEL_DIR = os.path.join(IMC_basedir, 'data/amelia_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, labels = utils.process_amelia(DATA_AMELIA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_r, Y_train_r, X_test_r, Y_test_r = utils.get_train_test_data(df, regression=True, train_size=0.8)\n",
    "X_train_c, Y_train_c, X_test_c, Y_test_c = utils.get_train_test_data(df, regression=False, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Benchmark Logistic Regression (Scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1.5year       0.62      0.74      0.68       187\n",
      "     4years       0.50      0.38      0.43       152\n",
      "       more       0.63      0.66      0.65        79\n",
      "\n",
      "avg / total       0.58      0.59      0.58       418\n",
      "\n",
      "Accuracy: 0.5933014354066986\n",
      "Mean square error (MSE): 0.54\n",
      "R^2: 0.59\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEbCAYAAAD6TW79AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb724dd6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create logistic regression object\n",
    "regr = linear_model.LogisticRegression()             \n",
    "regr.fit(X_train_c, Y_train_c) \n",
    "\n",
    "Y_pred = regr.predict(X_test_c)\n",
    "            \n",
    "utils.plot_report(Y_test_c, Y_pred, labels)\n",
    "\n",
    "# print ('Coefficients:', regr.coef_, regr.intercept_ )               \n",
    "print(\"Mean square error (MSE): %.2f\"\n",
    "      % np.mean((Y_pred - Y_test_c) ** 2))      # The mean square error\n",
    "print ('R^2: %.2f' % regr.score(X_test_c, Y_test_c) )  # Explained variance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regr = LinearSVC()\n",
    "regr.fit(X_train_r, Y_train_r) \n",
    "\n",
    "Y_pred = regr.predict(X_test_r)\n",
    "\n",
    "# print ('Coefficients:', regr.coef_, regr.intercept_ )               \n",
    "print(\"Mean square error (MSE): %.2f\"\n",
    "      % np.mean((Y_pred - Y_test_r) ** 2))      # The mean square error\n",
    "print ('R^2: %.2f' % regr.score(X_test_r, Y_test_r) )  # Explained variance score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Benchmark Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = LinearSVC(random_state=0)\n",
    "svc.fit(X_train_c, Y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = svc.predict(X_test_c)\n",
    "            \n",
    "utils.plot_report(Y_test_c, Y_pred, labels)\n",
    "\n",
    "# print ('Coefficients:', regr.coef_, regr.intercept_ )               \n",
    "print(\"Mean square error (MSE): %.2f\"\n",
    "      % np.mean((Y_pred - Y_test_c) ** 2))      # The mean square error\n",
    "print ('R^2: %.2f' % regr.score(X_test_c, Y_test_c) )  # Explained variance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = LinearSVC(random_state=0)\n",
    "svc.fit(X_train_r, Y_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = svc.predict(X_test_r)\n",
    "            \n",
    "# print ('Coefficients:', regr.coef_, regr.intercept_ )               \n",
    "print(\"Mean square error (MSE): %.2f\"\n",
    "      % np.mean((Y_pred - Y_test_r) ** 2))      # The mean square error\n",
    "print ('R^2: %.2f' % regr.score(X_test_r, Y_test_r) )  # Explained variance score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Classification: Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need the full dataset for cross validation\n",
    "X = df.copy(deep=True)\n",
    "\n",
    "Y = np.array(X['life_expectancy_bin'])\n",
    "# remove columns\n",
    "X.drop('life_expectancy', axis = 1, inplace=True)\n",
    "X.drop('life_expectancy_bin', axis = 1, inplace=True)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=54, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = cross_val_score(estimator, X, Y, cv=KFold(n=X.shape[0], n_folds=2, shuffle=True))\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Classification: Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Dense(108, input_shape=(54,), kernel_initializer='normal', activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(8, kernel_initializer='normal', activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(64, activation='relu', input_dim=54))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.add(Dense(input_dim=54, output_dim=12, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(input_dim=12, output_dim=12, activation='relu'))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(output_dim=1, activation='softmax'))\n",
    "# model.compile(loss='mean_squared_error', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "# 3\n",
    "#tbCallBack = keras.callbacks.TensorBoard(log_dir='/tmp/keras_logs', write_graph=True)\n",
    "\n",
    "# 4\n",
    "#model.compile(loss='mean_squared_error', optimizer='adadelta', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "hist = model.fit(np.array(X_train), np.array(to_categorical(Y_train)), \n",
    "                 epochs=600, batch_size=128,  verbose=1, validation_split=0.3)#, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist = model.fit(np.array(X_train), np.array(to_categorical(Y_train)), \n",
    "                 epochs=120, batch_size=128,  verbose=0, validation_split=0.3)#, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = Y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.plot_report(Y_test, Y_pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Classification: Ensamble of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_dim = 54, kernel_initializer='he_normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mp = mlp_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = mp.fit(np.array(X_train_c), np.array(to_categorical(Y_train_c)), epochs=600, batch_size=128,  verbose=0, \n",
    "              validation_split=0.3)#, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create 5 models to ensemble\n",
    "model1 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "model2 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "model3 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "model4 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "model5 = KerasClassifier(build_fn = mlp_model, epochs = 150)\n",
    "\n",
    "ensemble_clf = VotingClassifier(estimators = [('model1', model1), ('model2', model2), \n",
    "                                              ('model3', model3), ('model4', model4), \n",
    "                                              ('model5', model5)], voting = 'soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ensemble_clf.fit(np.array(X_train), np.array(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = ensemble_clf.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.plot_report(Y_test, Y_pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Regression: Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_kfolds(regressor, x, y, kfolds = [5]):\n",
    "    for k_folds in kfolds:\n",
    "        # evaluate model with standardized dataset\n",
    "        np.random.seed(182)\n",
    "        estimators = []\n",
    "        #estimators.append(('standardize', StandardScaler()))\n",
    "        estimators.append(('mlp', regressor))\n",
    "        pipeline = Pipeline(estimators)\n",
    "        kfold = KFold(n=X.shape[0], n_folds=k_folds)\n",
    "        results = cross_val_score(pipeline, x, y, cv=kfold)\n",
    "        print(\"K_folds {}: \\nMean {} \\nStd {}\".format(k_folds, results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need full dataset for cross validation\n",
    "X = df.copy(deep=True)\n",
    "\n",
    "Y = np.array(X['life_expectancy'])\n",
    "# remove columns\n",
    "X.drop('life_expectancy', axis = 1, inplace=True)\n",
    "X.drop('life_expectancy_bin', axis = 1, inplace=True)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define base model\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=54, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[metrics.MAPE,\n",
    "                                                                        metrics.MSLE,\n",
    "                                                                        metrics.MAE])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm = baseline_model()\n",
    "hist = bm.fit(np.array(X_train_r), np.array(Y_train_r), \n",
    "                 epochs=600, batch_size=128,  verbose=0, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.plot_hist(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_kfolds(KerasRegressor(build_fn=baseline_model, nb_epoch=150, batch_size=128, verbose=0), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm.evaluate(np.array(X_test_r), np.array(Y_test_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Regression: Keras NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(54, kernel_initializer=\"normal\", input_dim=54, activation=\"relu\"))\n",
    "    model.add(Dense(27, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(15, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_kfolds(KerasRegressor(build_fn=larger_model, nb_epoch=150, batch_size=128, verbose=0), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(540, kernel_initializer=\"normal\", input_dim=54, activation=\"relu\"))\n",
    "    model.add(Dense(270, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_kfolds(KerasRegressor(build_fn=wider_model, nb_epoch=150, batch_size=128, verbose=0), X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Model showdown\n",
    "\n",
    "Different approach for Classification vs. Regression using Neural Network:\n",
    "- Training examples: Rn x {class_1, ..., class_n} (one-hot encoding) vs Rn x Rm\n",
    "- Last layer: softmax vs linear / sigmoid\n",
    "- Loss function: Cross entropy vs MSE / Absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, kernel_initializer=\"normal\", input_dim=54))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "    \n",
    "model.compile(optimizer = optimizers.SGD(lr = 0.001), loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(np.array(X_train), np.array(Y_train), epochs = 100, verbose = 1)\n",
    "\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.legend(['training', 'validation'], loc = 'upper left')\n",
    "# plt.show()\n",
    "\n",
    "results = model.evaluate(np.array(X_test), np.array(Y_test))\n",
    "print('\\nTest accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/pybrain/pybrain.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 PyBrain: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybrain.structure import SigmoidLayer, LinearLayer, TanhLayer, ReluLayer, SoftmaxLayer\n",
    "from pybrain.datasets import SupervisedDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "import pybrain.tools.shortcuts as pb\n",
    "import numpy, math\n",
    "\n",
    "# Build the dataset\n",
    "xvalues = np.array(X_train_r)\n",
    "yvalues = np.array(Y_train_r)\n",
    "ds = SupervisedDataSet(54, 1)\n",
    "for x, y in zip(xvalues, yvalues):\n",
    "    ds.addSample((x), (y))\n",
    "    \n",
    "# Build the NN\n",
    "nn1 = pb.buildNetwork(54,  # 1 input node\n",
    "                   #108,    # number of nodes in 1st hidden layer\n",
    "                   54,     # number of nodes in 4th hidden layer\n",
    "                   1,     # 1 output node\n",
    "                   bias = False,\n",
    "                   hiddenclass = SigmoidLayer,\n",
    "                   outclass = LinearLayer )\n",
    "\n",
    "# Train the NN\n",
    "trainer = BackpropTrainer(nn1, ds, learningrate = 0.01, weightdecay=0.01, momentum=0.02) #, verbose = True)\n",
    "train_mse, validation_mse = trainer.trainUntilConvergence(maxEpochs = 20, continueEpochs=5, validationProportion=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note on some of the parameters\n",
    "\n",
    "**validationProportion**: ratio of the dataset that is used for the validation dataset.\n",
    "If maxEpochs is given, at most that many epochs are trained. Each time validation error hits a minimum, try for continueEpochs # epochs to find a better one.\n",
    "\n",
    "**Epoch**: one epoch means that every example has been seen once. It is preferable to track epochs rather than iterations since \n",
    "the number of iterations depends on the arbitrary setting of batch size. Batchs are used for example in the minibatch method,\n",
    "for example, for 1000 examples, the NN is trained on examples 1-100, then examples 101-201, etc.\n",
    "\n",
    "**Momentum**: 0 < m < 1 is a global parameter which must be determined by trial and error. Momentum simply adds a fraction m of the previous weight update to the current one. When the gradient keeps pointing in the same direction, this will increase the size of the steps taken towards the minimum. It is otherefore often necessary to reduce the global learning rate µ when using a lot of momentum (m close to 1). If you combine a high learning rate with a lot of momentum, you will rush past the minimum with huge steps! When the gradient keeps changing direction, momentum will smooth out the variations. Adding a momentum can help to speed up convergence to the minimum by damping oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning curves\n",
    "plt.clf()\n",
    "plt.plot(range(len(train_mse)), np.sqrt(train_mse), color='blue', label='training error')\n",
    "plt.plot(range(len(validation_mse)), np.sqrt(validation_mse), color='red', label='validation error')\n",
    "plt.title('Learning curves: loss(=RMSE) as a function of Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Tensorflow Deep Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dnn_classifier import DNNClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Current training accuracy: 0.5500\n",
      "Epoch: 11 Current training accuracy: 0.6000\n",
      "Epoch: 21 Current training accuracy: 0.4000\n",
      "Epoch: 31 Current training accuracy: 0.6000\n",
      "Epoch: 41 Current training accuracy: 0.7000\n",
      "Epoch: 51 Current training accuracy: 0.7000\n",
      "Epoch: 61 Current training accuracy: 0.5000\n",
      "Epoch: 71 Current training accuracy: 0.6500\n",
      "Epoch: 81 Current training accuracy: 0.6500\n",
      "Epoch: 91 Current training accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "dnn = DNNClassifier(show_progress=10, random_state=42)\n",
    "dnn.fit(np.array(X_train_c), np.array(Y_train_c), n_epochs=100)\n",
    "\n",
    "Y_pred = dnn.predict(X_test_c)\n",
    "print(\"Score on test set: {:.2f}%\".format(accuracy_score(Y_test_c, Y_pred) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try dropout to reduce overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Current training accuracy: 0.4500\n",
      "Epoch: 11 Current training accuracy: 0.6000\n",
      "Epoch: 21 Current training accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "dnn = DNNClassifier(dropout_rate=0.25, show_progress=10, random_state=42)\n",
    "dnn.fit(np.array(X_train_c), np.array(Y_train_c), n_epochs=1000)\n",
    "\n",
    "Y_pred = dnn.predict(X_test_c)\n",
    "print(\"Score on test set: {:.2f}%\".format(accuracy_score(Y_test_c, Y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
